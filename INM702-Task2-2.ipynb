{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63838887-9675-467e-8370-f534dfd2131f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "import torch.nn as nn\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score,roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efae692e-0e58-4f5b-b41e-280c90e60f19",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0242f928-2821-46ba-90b8-80882404230f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Shape: (57650, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>/a/abba/ahes+my+kind+of+girl_20598417.html</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\r\\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>/a/abba/andante+andante_20002708.html</td>\n",
       "      <td>Take it easy with me, please  \\r\\nTouch me gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>/a/abba/as+good+as+new_20003033.html</td>\n",
       "      <td>I'll never know why I had to go  \\r\\nWhy I had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>/a/abba/bang_20598415.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>/a/abba/bang+a+boomerang_20002668.html</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song                                        link  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl  /a/abba/ahes+my+kind+of+girl_20598417.html   \n",
       "1   ABBA       Andante, Andante       /a/abba/andante+andante_20002708.html   \n",
       "2   ABBA         As Good As New        /a/abba/as+good+as+new_20003033.html   \n",
       "3   ABBA                   Bang                  /a/abba/bang_20598415.html   \n",
       "4   ABBA       Bang-A-Boomerang      /a/abba/bang+a+boomerang_20002668.html   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\r\\nA...  \n",
       "1  Take it easy with me, please  \\r\\nTouch me gen...  \n",
       "2  I'll never know why I had to go  \\r\\nWhy I had...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./spotify_millsongdata.csv\")\n",
    "print(\"DF Shape:\",df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf3baa67-f373-4029-b1e3-188933ca4e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist    0\n",
       "song      0\n",
       "link      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b28f8a7d-676a-4b35-b8b0-3434c5985dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Encode Labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['artist'] = label_encoder.fit_transform(df['artist'])\n",
    "df = df.drop(['link'], axis=1, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55e3a304-26b2-40e1-8440-ab0a320b1321",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limit to 5000 features for efficiency\n",
    "X = tfidf_vectorizer.fit_transform(df['text']).toarray()\n",
    "y = df['artist'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35c1b56f-57f7-42f7-bb7f-412b26d8ee5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1246cb4a-6e5d-4d71-b4b7-49779bc5ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class SongDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "228fb789-eb47-4804-a9f1-a5bb8014ee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Batch Shape: torch.Size([32, 5000])\n",
      "Labels Batch Shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset Objects\n",
    "train_dataset = SongDataset(X_train, y_train)\n",
    "val_dataset = SongDataset(X_val, y_val)\n",
    "test_dataset = SongDataset(X_test, y_test)\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Check DataLoader\n",
    "for features, labels in train_loader:\n",
    "    print(\"Features Batch Shape:\", features.shape)\n",
    "    print(\"Labels Batch Shape:\", labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a6d084-279a-4e9a-a520-5579478a4a29",
   "metadata": {},
   "source": [
    "### Define a PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f5ab79b-ba35-4e89-a4f0-50b4d222221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SongClassifier(\n",
      "  (fc1): Linear(in_features=5000, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=643, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SongClassifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(SongClassifier, self).__init__()\n",
    "        \n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(input_size, 256)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(256, 128)        # Second fully connected layer\n",
    "        self.fc3 = nn.Linear(128, num_classes)  # Output layer\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)  # Dropout for regularization\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Forward pass through layers\n",
    "        x = F.relu(self.fc1(x))         # First layer with ReLU activation\n",
    "        x = self.dropout(x)             # Apply dropout\n",
    "        x = F.relu(self.fc2(x))         # Second layer with ReLU activation\n",
    "        x = self.dropout(x)             # Apply dropout\n",
    "        x = self.fc3(x)                 # Output layer (no activation here)\n",
    "        return x\n",
    "\n",
    "# Model Instantiation\n",
    "input_size = 5000  # Feature size from TF-IDF\n",
    "num_classes = len(label_encoder.classes_)  # Number of unique artists\n",
    "\n",
    "model = SongClassifier(input_size=input_size, num_classes=num_classes)\n",
    "\n",
    "# Print Model Summary\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7fe474-f25f-4231-96dd-1f270dc84326",
   "metadata": {},
   "source": [
    "### Define Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45e42f05-1a83-4ce0-8a7e-d0389abe4180",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf1ee7c-60dd-43ea-bdd4-6211e29e635c",
   "metadata": {},
   "source": [
    "### Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b433594e-f35e-44d3-902a-ea1662762116",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc18fcf7-6876-43ad-89fb-377b9df41b58",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3143434-faa5-41c6-bf23-9cac6af11958",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SongClassifier(input_size=5000, num_classes=643)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Training Loop Parameters\n",
    "num_epochs = 10\n",
    "train_losses, val_losses = [], []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e31c1e07-d54a-41e7-ba8c-1c9b8ce99d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features Shape: torch.Size([32, 5000])\n",
      "Labels Shape: torch.Size([32])\n",
      "Features: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Labels: tensor([292, 348, 384, 286, 461, 123, 196,  33, 567, 180, 490, 536,  70, 412,\n",
      "          6, 392,  99,  62,  11, 618,  64, 153, 238,  59,  77, 227, 120, 612,\n",
      "        362, 275, 514, 198])\n"
     ]
    }
   ],
   "source": [
    "for features, labels in train_loader:\n",
    "    print(\"Features Shape:\", features.shape)\n",
    "    print(\"Labels Shape:\", labels.shape)\n",
    "    print(\"Features:\", features)\n",
    "    print(\"Labels:\", labels)\n",
    "    break  # Exit after inspecting the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def560d-072e-46ce-97a7-86e79e825652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Loss:1.6171\n",
      "Epoch: 10 - Loss:1.1255\n",
      "Epoch: 20 - Loss:0.8839\n",
      "Epoch: 30 - Loss:0.7497\n",
      "Epoch: 40 - Loss:0.6621\n",
      "Epoch: 50 - Loss:0.6186\n",
      "Epoch: 60 - Loss:0.5726\n",
      "Epoch: 70 - Loss:0.5369\n",
      "Epoch: 80 - Loss:0.5030\n",
      "Epoch: 90 - Loss:0.4771\n",
      "Epoch: 100 - Loss:0.4577\n",
      "Epoch: 110 - Loss:0.4423\n",
      "Epoch: 120 - Loss:0.4323\n",
      "Epoch: 130 - Loss:0.4081\n",
      "Epoch: 140 - Loss:0.4041\n"
     ]
    }
   ],
   "source": [
    "#Define function to train the network\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_epochs = 50\n",
    "batch_size= 128\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss= 0.0\n",
    "    \n",
    "    #Explicitly start model training\n",
    "    model.train()\n",
    "    \n",
    "    for features, labels in train_loader:\n",
    "        #Extract train batch from X and Y\n",
    "        \n",
    "        input_data, labels = features.to(device), labels.to(device)\n",
    "\n",
    "        #set the gradients to zero before starting to do backpropragation\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #Forward pass using model and the train data\n",
    "        outputs = model(input_data)  \n",
    "\n",
    "        #Caculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        #Backpropogate\n",
    "        loss.backward()\n",
    "        \n",
    "        #Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print(\"Epoch: {} - Loss:{:.4f}\".format(epoch,train_loss / len(train_loader) ))\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "# Training Complete\n",
    "print(\"Training finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb2d7a6-31ce-4ee4-a937-6bbe9c7fe93f",
   "metadata": {},
   "source": [
    "## Validation check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10012142-2bfb-4ab4-9845-f41d7131faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for evaluating NN\n",
    "\n",
    "model.eval() #Explicitly set to evaluate mode\n",
    "\n",
    "#Predict on Train and Validation Datasets\n",
    "test_prob = model(test_loader)\n",
    "test_pred =np.where(test_prob>0.5,1,0)\n",
    "train_prob = model(train_loader)\n",
    "train_prob =np.where(train_prob>0.5,1,0)\n",
    "\n",
    "#Compute Training and Validation Metrics\n",
    "print(\"\\n Model Performance -\")\n",
    "print(\"Training Accuracy-\",round(accuracy_score(train_loader,train_pred),3))\n",
    "print(\"Training Precision-\",round(precision_score(train_loader,train_pred),3))\n",
    "print(\"Training Recall-\",round(recall_score(train_loader,train_pred),3))\n",
    "print(\"Training ROCAUC\", round(roc_auc_score(train_loader\n",
    "                               ,train_pred.detach().numpy()),3))\n",
    "print(\"Validation Accuracy-\",round(accuracy_score(test_loader,test_pred),3))\n",
    "print(\"Validation Precision-\",round(precision_score(test_loader,test_pred),3))\n",
    "print(\"Validation Recall-\",round(recall_score(test_loader,test_pred),3))\n",
    "print(\"Validation ROCAUC\", round(roc_auc_score(test_loader\n",
    "                                 ,test_prob.detach().numpy()),3))\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "#Plot the Loss curve and ROC Curve\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss_list)\n",
    "plt.title('Loss across epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "\n",
    "#Validation\n",
    "fpr_v, tpr_v, _ = roc_curve(test_loader, test_prob.detach().numpy())\n",
    "roc_auc_v = auc(fpr_v, tpr_v)\n",
    "\n",
    "\n",
    "#Training\n",
    "fpr_t, tpr_t, _ = roc_curve(train_loader, train_prob.detach().numpy())\n",
    "roc_auc_t = auc(fpr_t, tpr_t)\n",
    "plt.title('Receiver Operating Characteristic:Validation')\n",
    "plt.plot(fpr_v, tpr_v, 'b', label = 'Validation AUC = %0.2f' % roc_auc_v)\n",
    "plt.plot(fpr_t, tpr_t, 'r', label = 'Training AUC = %0.2f' % roc_auc_t)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89c17b6-5902-4229-bfdc-3e8af5f726ee",
   "metadata": {},
   "source": [
    "### Preparing data for pytorch and spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a926c77-775a-4b04-b1cb-1621b0fd3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cffe58f-eb80-4b9e-82f8-85c19ca41c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset\n",
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=128):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        lyric = self.data.iloc[index]['text']\n",
    "        label = self.data.iloc[index]['artist']\n",
    "        encoding = self.tokenizer(lyric, truncation=True, padding='max_length', max_length=self.max_len, return_tensors=\"pt\")\n",
    "        return encoding['input_ids'].squeeze(0), encoding['attention_mask'].squeeze(0), torch.tensor(label)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Datasets\n",
    "train_dataset = LyricsDataset(train_data, tokenizer)\n",
    "test_dataset = LyricsDataset(test_data, tokenizer)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44b90358-c98b-487a-aab2-b5b512b32c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class NeuralNetworkClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(2020)\n",
    "        self.fc1 = nn.Linear(14, 30)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.fc2 = nn.Linear(30, 30)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.fc3 = nn.Linear(30, 5)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.out = nn.Linear(5, 1)\n",
    "        self.final = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        op = self.fc1(x)\n",
    "        op = self.relu1(op)\n",
    "        \n",
    "        op = self.fc2(op)\n",
    "        op = self.relu2(op)\n",
    "\n",
    "        op = self.fc3(op)\n",
    "        op = self.relu3(op)\n",
    "\n",
    "        op = self.out(op)\n",
    "        y = self.final(op)\n",
    "        \n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28851257-7a07-42fd-8388-b884e4e7149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "batch_size= 128\n",
    "loss_function = nn.MSELoss()  #Binary Crosss Entropy Loss\n",
    "\n",
    "#Hyperparameters\n",
    "weight_decay=0.0 #set to 0; no L2 Regularizer; passed into the Optimizer\n",
    "lambda_L1=0.0    #Set to 0; no L1 reg; manually added in loss (train_network)\n",
    "\n",
    "#Create a model instance\n",
    "model = NeuralNetworkClassifier()\n",
    "\n",
    "adam_optimizer = torch.optim.Adam(model.parameters(), lr= 0.001,weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "# Model Parameters\n",
    "vocab_size = tokenizer.vocab_size\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "output_dim = len(label_encoder.classes_)\n",
    "pad_idx = tokenizer.pad_token_id\n",
    "\n",
    "# Model\n",
    "model = LyricsClassifier(vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx)\n",
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f714243b-8ec5-473c-b79c-eb880107a1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 6.2857\n",
      "Epoch 2, Loss: 6.1994\n",
      "Epoch 3, Loss: 6.1124\n",
      "Epoch 4, Loss: 6.0050\n",
      "Epoch 5, Loss: 5.8683\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for epoch in range(10):  # Number of epochs\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for input_ids, attention_mask, labels in train_loader:\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a7087-7866-4893-a155-05de062744a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask, labels in test_loader:\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60840d5-e93b-40b4-b1f9-d2c28ff0fc33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
